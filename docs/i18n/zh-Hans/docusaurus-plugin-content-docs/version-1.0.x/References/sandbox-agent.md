---
sidebar_position: 3
---

# 沙箱代理 (Sandbox Agent)（实验性）

沙箱代理是ROCK框架中用于在隔离环境中运行AI智能体任务的组件，提供安全且可控制的智能体执行环境。代理可以与模型服务(Model Service)集成，实现LLM模型调用的优雅处理。

## 架构概述

沙箱代理通过在隔离的沙箱环境中初始化和执行智能体任务，包括安装必要的依赖、配置运行环境等步骤。代理系统支持多种不同的智能体类型，如SWE-agent和IFlow CLI等，每种类型都有其特定的配置和实现方式。

代理可以与模型服务集成，在任务执行期间处理AI模型调用。当代理需要查询或调用AI模型时，模型服务会在后台处理模型通信，使代理专注于任务执行。


## Sandbox Agent 初始化流程

1. 创建沙箱环境和代理实例
2. 调用`init()`方法初始化代理
3. 在沙箱中创建专用的bash会话
4. 执行预启动命令（如环境配置）
5. 安装必要的依赖（Python、Node.js等）
6. 安装特定的智能体工具（如SWE-agent或IFlow CLI）
7. 如果配置了模型服务，将同步初始化模型服务

## Sandbox Agent 执行流程

1. 准备任务运行参数（问题陈述、项目路径等）
2. 调用`run()`方法执行任务
3. 准备运行所需的配置文件, 并将配置文件上传到沙箱环境(如果需要)
4. 执行Agent
6. 如果配置了模型服务，同步监控Agent进程
7. 等待任务完成并返回结果

## Model Service 集成能力

沙箱Agent支持与模型服务的无缝集成，为AI模型调用提供通信桥梁。这种集成允许Agent通过文件系统通信协议与模型服务交互，实现异步的请求-响应机制。在Agent初始化时, 可以将Agent请求的LLM地址配置为model-service server的地址(如默认提供http://localhost:8080/v1/chat/completions), 从而利用model-service代理访问实际推理服务; 当Agent与模型服务集成时的工作流程:

### 任务开始前
1. 调用`start_model_service()`启动模型服务
2. 调用`watch_agent()`设置对Agent进程的监控

### Agent调用LLM时
1. Agent发起模型调用请求
2. 请求通过文件通信协议写入文件
3. 模型服务监听器捕获请求
4. 实际的AI模型返回响应
5. 响应通过文件通信协议写回
6. Agent读取响应并继续执行